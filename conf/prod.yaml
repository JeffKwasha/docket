---
# Configure your stenographer instances here. sensor is a just an arbitrary unique name
STENOGRAPHER_INSTANCES:
    - { host: 127.0.0.1, sensor: sensor-1, port: 1234, key: /etc/stenographer/certs/client_key.pem, cert: /etc/stenographer/certs/client_cert.pem, ca: /etc/stenographer/certs/ca_cert.pem }

# Flask config values
DEBUG: false
TESTING: false
SECRET_KEY: CHANGE_THIS_SECRET_KEY_TO_ANY_RANDOM_VALUE
SESSION_COOKIE_NAME: DOCKET_SESSION
USE_X_SENDFILE: false

# Celery configuration - CELERY_URL is many things :/
CELERY_URL: redis://localhost:6379
# all results are simply written to disk, at the moment there's no need to care about brokering them
CELERY_TASK_IGNORE_RESULT: true

# Docket configuration
# SPOOL_DIR     - where captures are saved and served - if you change this make sure to fix the webserver's static file configuration
SPOOL_DIR: /var/spool/docket/
# WEB_ROOT      - the base url for all docket requests: 
# WEB_ROOT=/foo/ => http://HOST:PORT/foo/status, http://HOST:PORT/foo/q/after/5m/host/1.2.3.4
WEB_ROOT: /
# DATE_FORMAT   - strftime format for showing a datetime to a user, not used yet
DATE_FORMAT: '%Y%jT%H:%M:%S'
# Logging configuration
LOGGER_NAME: docket
# LOG_LEVEL  (error, warning, info, debug) any other value will be ignored
LOG_LEVEL: info
LOG_MSG_FORMAT: "[%(processName)-8s:%(thread)d] %(message)s"
LOG_DATE_FORMAT: '%Y-%m-%dT%H:%M:%SZ'
LOG_DATE_UTC: True
# LOG_FILE   a secondary logging handler - this file will be rotated at midnight
LOG_FILE: /var/log/docket/docket.log
LOG_FILE_MSG_FORMAT: "%(asctime)s[%(processName)-8s:%(thread)d] %(message)s"
#LOG_DATE_FORMAT: '%Y-%m-%dT%H:%M:%SZ'  # ISO
LOG_FILE_DATE_FORMAT: '%Y%jT%H:%M:%S'
LOG_FILE_LEVEL: debug

# TIME_WINDOW  Integer: specifies the size of a time 'chunk' in seconds for request de-duplication
#              Requested times are widened to a multiple of this value.
TIME_WINDOW: 60
# IDLE_TIME     - 5.0, assume stenoboxes remain IDLE for 5 seconds and check again after that.
# IDLE_SLEEP    - 2.0, wait time between IDLE queries. will occur at least once every IDLE_TIME.
# STAT_TIMEOUT  - 3.0, assume a stenobox is broken if stats doesn't return within this many seconds
# QUERY_TIMEOUT - 720, assume stenoboxes are broken if a query doesn't return within this many seconds
# LOCK_TIMEOUT  - 2.0, seconds to wait on a file lock before giving up.
IDLE_TIME: 5.0
IDLE_SLEEP: 2.0
STAT_TIMEOUT: 3.0
QUERY_TIMEOUT: 720.0
LOCK_TIMEOUT: 2.0

# MERGED_NAME   - base name (no extension) of the result capture file. Just a string.
MERGED_NAME: merged
# QUERY_NAME    - base name of the query extended save file. Just a string.
QUERY_NAME: query
# LONG_AGO      - The default 'after' clause isn't 1970, but this long before now()
LONG_AGO: 24h

# WEIGHTS       - request 'weight' can be estimated to prevent clogging up the system.  
#               - Estimate the amount of data in the system (total buffered packet data)
#               - Pick a threshold for a single request 1% * (TOTAL / 8 hours / 60 minutes / 5 requests per minute)
#               - IPs  - the number of (active) IPs captured
#               - NETS - the number of (active) subnets captured
#               - PORTs- the number of (active) Ports per IP
#               - HOURS- the number of hours in the buffer (I know variance is likely above 50%)
#               - 'weight' = (TOTAL / (HOURS * 3600) * QUERY_SECONDS) / ( SUM(IPs + NETs) * SUM( PORTs )
#  ex: a 5TB/8hour system, query: 1 IP and 1 port for 10 seconds == 381774 == 380KB
#  5TB / (8 * 3600) * 10seconds / ( (50.0 * 1ip + 2 * 0net) * 100.0 * 1port )
#               NOTE: Raw queries are not weighed or widened so only identical raw queries are deduplicated.
#WEIGHT_TOTAL:     5TB      # valid quantifiers( B KB MB GB TB PB )
#WEIGHT_THRESHOLD: 22MB     # valid quantifiers( B KB MB GB TB PB )
#WEIGHT_IPS: 50.0
#WEIGHT_NETS: 2.0
#WEIGHT_PORTS: 100.0
#WEIGHT_HOURS: 8.0

# EXPIRE_SPACE  - if set, the oldest items will be removed until this much space becomes available.
# EXPIRE_TIME   - how long after last 'touch' does a request expire ?
# CLEANUP_PERIOD - delete expired queries will run every CLEANUP_PERIOD seconds
EXPIRE_SPACE: 100MB
EXPIRE_TIME: 1h
CLEANUP_PERIOD: 1h

# ID_FORMAT:    - if set to a single dash '-' will use the standard GUID format for request IDs
ID_FORMAT: false

# Stop accepting requests if SPOOL_DIR's free space or nodes go below these values:
FREE_BYTES: 100MB
FREE_NODES: 10111
